{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "\n",
    "\n",
    "list_of_roles = ['LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM',\n",
    "                 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM', 'CDM', 'RDM', 'RWB', 'LB', 'LCB', \n",
    "                 'CB', 'RCB', 'RB']\n",
    "\n",
    "fifa_stats = ['Crossing', 'Finishing', 'Heading Accuracy',\n",
    "              'Short Passing', 'Volleys', 'Dribbling', 'Curve',\n",
    "              'Free Kick Accuracy', 'Long Passing', 'Ball Control',\n",
    "              'Acceleration', 'Sprint Speed', 'Agility', 'Reactions',\n",
    "              'Balance', 'Shot Power', 'Jumping', 'Stamina', 'Strength',\n",
    "              'Long Shots', 'Aggression', 'Interceptions', 'Positioning',\n",
    "              'Vision', 'Penalties', 'Composure', 'Marking', 'Standing Tackle',\n",
    "              'Sliding Tackle', 'GK Diving', 'GK Handling', 'GK Kicking',\n",
    "              'GK Positioning', 'GK Reflexes']\n",
    "\n",
    "cols =['full_name', 'player_id', 'age', 'rating', 'potential', 'club', 'club_joined', \n",
    "       'contract_valid', 'value', 'wage', 'release_clause', 'preff_foot',\n",
    "       'Acceleration', 'Aggression', 'Agility', 'Balance', 'Ball Control',\n",
    "       'Composure', 'Crossing', 'Curve', 'DOB', 'Dribbling', 'Finishing',\n",
    "       'GK Diving', 'GK Handling', 'GK Kicking', 'GK Positioning',\n",
    "       'GK Reflexes', 'Heading Accuracy', 'Interceptions', 'Jumping',\n",
    "       'Long Passing', 'Long Shots', 'Marking', 'Penalties', 'Positioning',\n",
    "       'Reactions', 'Short Passing', 'Shot Power', 'Sliding Tackle',\n",
    "       'Sprint Speed', 'Stamina', 'Standing Tackle', 'Strength', 'Vision',\n",
    "       'Volleys', 'club_jersey', 'club_pos',\n",
    "       'country', 'country_jersey', 'country_pos',\n",
    "       'country_rating','height', 'international_rep', \n",
    "       'traits', 'weight', 'LS', 'ST', 'RS', 'LW', 'LF', 'CF', 'RF', 'RW', 'LAM', 'CAM', 'RAM', 'LM',\n",
    "                 'LCM', 'CM', 'RCM', 'RM', 'LWB', 'LDM', 'CDM', 'RDM', 'RWB', 'LB', 'LCB', \n",
    "                 'CB', 'RCB', 'RB']\n",
    "# We will create a list of url that gives all the pages of the players from sofifa\n",
    "# Start and end should be between 0 and 226\n",
    "\n",
    "def url_list_generator(start, end):\n",
    "    \n",
    "    l =[]\n",
    "    \n",
    "    url_list = []\n",
    "    \n",
    "    for x in range(226):\n",
    "        l.append(x*80)\n",
    "        \n",
    "    for i in l:\n",
    "        url_list.append('https://sofifa.com/players?showCol=jt&col=oa&sort=desc&offset={}'.format(i))\n",
    "        \n",
    "    url_list[0] ='https://sofifa.com/players'\n",
    "    \n",
    "    return url_list[start:end]\n",
    "\n",
    "# soup_maker will generate the soup obj of a given url and the corresponding webpage\n",
    "\n",
    "def soup_maker(url):\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    \n",
    "    markup = r.content\n",
    "    \n",
    "    soup = bs(markup, 'lxml')\n",
    "    \n",
    "    return soup\n",
    "\n",
    "# find_top_players will extract the links of  each 80 players\n",
    "\n",
    "def find_top_players(soup):\n",
    "    \n",
    "    ## soup : Comes from soup_maker function. \n",
    "    ## soup object of a webpage like -- https://sofifa.com/players?offset=80\n",
    "    ## This function returns a list of url's of player websites each url is a string type\n",
    "    \n",
    "    player_id = []\n",
    "    \n",
    "    table = soup.findAll('table', {'class': 'table-hover'})\n",
    "    \n",
    "    tbody = table[0].find('tbody')\n",
    "    \n",
    "    all_a = tbody.find_all('a')\n",
    "    \n",
    "    for player in all_a:\n",
    "        \n",
    "        if  player['href'].startswith('/player/'):\n",
    "            player_id.append(player['href'])\n",
    "            \n",
    "    return ['http://sofifa.com' + player for player in player_id]\n",
    "\n",
    "# find_player_info extract the most basic info for a player.\n",
    "\n",
    "    \n",
    "def find_player_info(soup):\n",
    "    \n",
    "    ## Here soup comes from soup_maker(url). url will be a player's webpage link.\n",
    "    ## Return a dictionary that has the basic features of a player like name, id, dob, height and weight.\n",
    "    \n",
    "    player_data = {}\n",
    "    \n",
    "    player_data['full_name'] = soup.find('h1').text.split('(')[0]\n",
    "   \n",
    "    player_data['player_id'] = int(re.findall('\\d\\S\\d*' ,soup.find('h1').text.split('(')[1])[0])\n",
    "    \n",
    "    player_data['role'] = soup.find('div', {'class': 'info'}).find_all('span', {'class':'pos'})[0].text\n",
    "    \n",
    "    # meta (Age -- (Apr 4, 1987) 170cm 75KG)\n",
    "    meta = soup.find('div', {'class':'meta'}).contents[-1]\n",
    "    \n",
    "    # Create pattern to matcht () and numbers later in meta\n",
    "    # pattern.findall(meta) = ['(Jul 1, 1989)']\n",
    "    # pattern_digit.findall(meta) = ['30', '1', '1989', '170', '85']\n",
    "    \n",
    "    pattern = re.compile(r'\\(.+\\)')\n",
    "    \n",
    "    pattern_digit = re.compile(r'\\d+')\n",
    "    \n",
    "    player_data['DOB'] = pattern.findall(meta)[0].replace(',','').lstrip('(').rstrip(')')\n",
    "    \n",
    "    player_data['age'] = int(pattern_digit.findall(meta)[0])\n",
    "    \n",
    "    player_data['height'] = int(pattern_digit.findall(meta)[3])\n",
    "    \n",
    "    player_data['weight'] = int(pattern_digit.findall(meta)[4])\n",
    "    \n",
    "    return player_data\n",
    "\n",
    "# for url in ten_player:\n",
    "#     soup = soup_maker(url)\n",
    "#     info = soup.find('div', {'class': 'stats'}).find_all('div', {'class':'column'})\n",
    "\n",
    "def find_player_stats(info):\n",
    "    \n",
    "    player_data = {}\n",
    "    \n",
    "    player_data['rating'] = int(info[0].span.text)\n",
    "    \n",
    "    player_data['potential'] = int( info[1].span.text.lstrip('p'))\n",
    "    \n",
    "    player_data['value'] = info[2].span.text.lstrip('€')\n",
    "    \n",
    "    player_data['wage'] = info[3].span.text.lstrip('€')\n",
    "    \n",
    "    return player_data\n",
    "\n",
    "# for url in ten_player:\n",
    "#     soup = soup_maker(url)\n",
    "\n",
    "#     player_soup_box = soup.find('div', {'class':'player'}) \\\n",
    "#                                 .find('div', {'class':'card'}) \\\n",
    "#                                 .find('div',{'class': 'columns'}) \\\n",
    "#                                 .find_all('div',{'class': 'column'})\n",
    "    \n",
    "def find_player_secondary_info(player_soup_box, soup):\n",
    "\n",
    "    player_data = {}\n",
    "\n",
    "    player_data['preff_foot'] = player_soup_box[0]\\\n",
    "                                    .find_all('li')[0]\\\n",
    "                                    .text.strip('\\nPreferred Foot')\\\n",
    "                                    .rstrip()\n",
    "\n",
    "    player_data['international_rep'] = int(player_soup_box[0]\\\n",
    "                                                .find_all('li')[1].text\\\n",
    "                                                .strip('\\nInternational Reputation')\\\n",
    "                                                .rstrip())\n",
    "    \n",
    "    if soup.find('label', text='Joined'):\n",
    "        player_data['release_clause'] = player_soup_box[0]\\\n",
    "                                            .find('ul')\\\n",
    "                                            .find_all('li')[-1]\\\n",
    "                                            .contents[-2]\\\n",
    "                                            .text\\\n",
    "                                            .lstrip('€')\n",
    "\n",
    "\n",
    "    player_data['club'] = player_soup_box[2]\\\n",
    "                             .find('ul')\\\n",
    "                             .find_all('li')[0]\\\n",
    "                             .text.lstrip()\n",
    "\n",
    "    player_data['club_pos'] = player_soup_box[2]\\\n",
    "                                .find('ul')\\\n",
    "                                .find_all('li')[2]\\\n",
    "                                .contents[2]\\\n",
    "                                .text\n",
    "\n",
    "    player_data['club_jersey'] = int(player_soup_box[2]\\\n",
    "                                         .find('ul')\\\n",
    "                                         .find_all('li')[3]\\\n",
    "                                         .contents[1]\\\n",
    "                                         .rstrip())\n",
    "\n",
    "    if soup.find('label', text='Joined'):\n",
    "        player_data['club_joined'] = player_soup_box[2]\\\n",
    "                                            .find('ul')\\\n",
    "                                            .find_all('li')[4]\\\n",
    "                                            .contents[2]\\\n",
    "                                            .rstrip()\n",
    "        \n",
    "    if soup.find('label', text = 'Loaned From'):\n",
    "        player_data['club_joined'] = 'Loaned From ' + player_soup_box[2]\\\n",
    "                                                        .find('ul')\\\n",
    "                                                        .find_all('li')[4]\\\n",
    "                                                        .contents[2]\\\n",
    "                                                        .text \n",
    "\n",
    "    player_data['contract_valid'] = player_soup_box[2]\\\n",
    "                                            .find('ul')\\\n",
    "                                            .find_all('li')[5]\\\n",
    "                                            .contents[2]\\\n",
    "                                            .rstrip()\n",
    "\n",
    "    if len(player_soup_box) > 3:\n",
    "            player_data['country'] = player_soup_box[3]\\\n",
    "                                            .find('ul')\\\n",
    "                                            .find_all('li')[0]\\\n",
    "                                            .a\\\n",
    "                                            .text\n",
    "                            \n",
    "            player_data['country_rating'] = int(player_soup_box[3]\\\n",
    "                                                    .find('ul')\\\n",
    "                                                    .find_all('li')[1]\\\n",
    "                                                    .contents[0]\\\n",
    "                                                    .text)\n",
    "            \n",
    "            player_data['country_pos'] = player_soup_box[3]\\\n",
    "                                            .find('ul')\\\n",
    "                                            .find_all('li')[2]\\\n",
    "                                            .contents[2]\\\n",
    "                                            .text\n",
    "                            \n",
    "            player_data['country_jersey']= int(player_soup_box[3]\\\n",
    "                                                   .find('ul')\\\n",
    "                                                   .find_all('li')[3]\n",
    "                                                   .contents[1]\\\n",
    "                                                    .rstrip())\n",
    "            \n",
    "    return player_data\n",
    "\n",
    "def player_roles(soup):\n",
    "    \n",
    "    player_data = {}\n",
    "    \n",
    "    pattern = re.compile(r'\\d+')\n",
    "    \n",
    "    for i in range(0,6):\n",
    "        \n",
    "        for div in  soup[i].find_all('div', {'class':'column'}):\n",
    "            \n",
    "            for roles in list_of_roles:\n",
    "                \n",
    "                if roles in div.text:\n",
    "                    player_data[roles] = pattern.findall(div.contents[-1])[0]\n",
    "                    \n",
    "    return player_data\n",
    "\n",
    "def player_fifa_info(fifa_info):\n",
    "    \n",
    "    player_data = {}\n",
    "    \n",
    "    col_list = []\n",
    "    \n",
    "    for i in range(0,7):\n",
    "        col_list.extend(fifa_info[i].find('div').find_all('li'))\n",
    "        \n",
    "    pattern_digit = re.compile(r'\\d+')\n",
    "    \n",
    "    for stats in fifa_stats:\n",
    "        \n",
    "        for li in col_list:\n",
    "            \n",
    "            if stats in li.text:\n",
    "                player_data[stats] = int(pattern_digit.findall(li.text)[0])\n",
    "                \n",
    "    return player_data\n",
    "\n",
    "def player_traits_info(soup):\n",
    "    \n",
    "    player_traits_list = []\n",
    "    \n",
    "    player_data = {}\n",
    "    \n",
    "    for li in soup:\n",
    "        player_traits_list.append(li.text)\n",
    "        \n",
    "    player_data['traits'] = player_traits_list\n",
    "    \n",
    "    return player_data\n",
    "\n",
    "def player_all_details(url):\n",
    "    \n",
    "    all_details = {}\n",
    "    \n",
    "    soup = soup_maker(url)\n",
    "\n",
    "    all_details.update(find_player_info(soup))\n",
    "\n",
    "    info = soup.find('div', {'class': 'stats'})\\\n",
    "                   .find_all('div', {'class':'column'})\n",
    "\n",
    "    all_details.update(find_player_stats(info))\n",
    "\n",
    "    player_soup_box = soup.find('div', {'class':'player'}).find('div', {'class':'card'})\\\n",
    "                    .find('div',{'class': 'columns'})\\\n",
    "                    .find_all('div',{'class': 'column'})\n",
    "\n",
    "    all_details.update(find_player_secondary_info(player_soup_box, soup))\n",
    "\n",
    "    fifa_info_soup = soup.find_all('div', {'class': 'column col-4 mb-20'})\n",
    "\n",
    "    all_details.update(player_fifa_info(fifa_info_soup))\n",
    "    \n",
    "    overall_rating_soup = soup.find('h5', text = 'Real Overall Rating')\n",
    "    \n",
    "    if overall_rating_soup:\n",
    "        \n",
    "        s = soup.find_all('div', {'class':'toast mb-20'})[1].find_all('div',{'class':'columns'})\n",
    "        \n",
    "        all_details.update(player_roles(s))\n",
    "        \n",
    "    if soup.find('h5', text = 'Traits'):\n",
    "        \n",
    "        traits_soup = soup.find('ul', {'class': 'pl mb-20'}).find_all('li')\n",
    "        \n",
    "        all_details.update(player_traits_info(traits_soup))\n",
    "    \n",
    "    \n",
    "        \n",
    "    return all_details\n",
    "\n",
    "def data_frame_generator(start, end):\n",
    "    player_url_list = []\n",
    "    pages = url_list_generator(start,end)\n",
    "    df = pd.DataFrame()\n",
    "    for main_page_url in pages:\n",
    "        soup = soup_maker(main_page_url)\n",
    "        player_url_list = find_top_players(soup)\n",
    "        for i, url in enumerate(player_url_list):\n",
    "            try:\n",
    "                df = df.append(pd.DataFrame.from_dict(player_all_details(url), orient='index').T, ignore_index= True)\n",
    "                df.to_csv('player_list_226.csv')\n",
    "                if i%40 == 0:\n",
    "                    print('En son kaydedilen url: {}'.format(url))\n",
    "                    print('En son kaydedilen main_page: {}'.format(main_page_url))\n",
    "\n",
    "            except:\n",
    "                print('Hata for the url: {}'.format(url))\n",
    "                print('Hata main_page: {}'.format(main_page_url))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def find_player_nationality(url):\n",
    "\n",
    "        ## Here soup comes from soup_maker(url). url will be a player's webpage link.\n",
    "        ## Return a dictionary that has the basic features of a player like name, id, dob, height and weight.\n",
    "        soup = soup_maker(url)\n",
    "        player_data = {}\n",
    "\n",
    "        player_data['player_id'] = int(re.findall('\\d\\S\\d*' ,soup.find('h1').text.split('(')[1])[0])\n",
    "\n",
    "        player_data['nationality'] = soup.find_all('div', {'class':'meta'})[0].a.get('title')\n",
    "\n",
    "        return player_data\n",
    "    \n",
    "def nationality_generator(start, end):\n",
    "    player_url_list = []\n",
    "    pages = url_list_generator(start,end)\n",
    "    df = pd.DataFrame()\n",
    "    for main_page_url in pages:\n",
    "            soup = soup_maker(main_page_url)\n",
    "            player_url_list = find_top_players(soup)\n",
    "            for i, url in enumerate(player_url_list):\n",
    "                try:\n",
    "                    df = df.append(pd.DataFrame.from_dict(find_player_nationality(url), orient='index').T, ignore_index= True)\n",
    "                    df.to_csv('player_nationality_26.csv')\n",
    "                    if i%40 == 0:\n",
    "                        print('En son kaydedilen url: {}'.format(url))\n",
    "                        print('En son kaydedilen main_page: {}'.format(main_page_url))\n",
    "\n",
    "                except:\n",
    "                    print('Hata for the url: {}'.format(url))\n",
    "                    print('Hata main_page: {}'.format(main_page_url))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nationality_generator(26,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
